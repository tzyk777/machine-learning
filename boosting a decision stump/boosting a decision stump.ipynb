{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\zeyang\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2825: DtypeWarning: Columns (19,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "loans = pd.DataFrame.from_csv('lending-club-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['grade',              # grade of the loan\n",
    "            'term',               # the term of the loan\n",
    "            'home_ownership',     # home ownership status: own, mortgage or rent\n",
    "            'emp_length',         # number of years of employment\n",
    "           ]\n",
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "del loans['bad_loans']\n",
    "target = 'safe_loans'\n",
    "loans = loans[features + [target]]\n",
    "loans = loans.reset_index(drop=True)\n",
    "loans = pd.get_dummies(loans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = loans.ix[pd.read_json('module-8-assignment-2-train-idx.json')[0]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = loans.ix[pd.read_json('module-8-assignment-2-test-idx.json')[0]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intermediate_node_weighted_mistakes(labels_in_node, data_weights):\n",
    "    weighted_mistakes_all_positive = np.sum((labels_in_node != 1) * data_weights)\n",
    "    \n",
    "    weighted_mistakes_all_negative = np.sum((labels_in_node != -1) * data_weights)\n",
    "    \n",
    "    if weighted_mistakes_all_positive <= weighted_mistakes_all_negative:\n",
    "        return weighted_mistakes_all_positive, 1\n",
    "    return weighted_mistakes_all_negative, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quiz Question: If we set the weights α=1 for all data points, how is the weight of \n",
    "# mistakes WM(α,y^) related to the classification error?\n",
    "\n",
    "# Identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def best_splitting_feature(data, features, target, data_weights):\n",
    "    best_feature = None\n",
    "    best_error = float('+inf')\n",
    "    \n",
    "    for feature in features:\n",
    "        left_split = data[data[feature] == 0]\n",
    "        right_split = data[data[feature] == 1]\n",
    "        \n",
    "        #print('Left ' ,len(left_split))\n",
    "        #print('Right ', len(right_split))\n",
    "        #print('Total ', len(data_weights))\n",
    "        left_data_weights = data_weights[np.where(data[feature] == 0)]\n",
    "        right_data_weights = data_weights[np.where(data[feature] == 1)]\n",
    "        #print(len(left_split[target].as_matrix()))\n",
    "        #print(len(left_data_weights))\n",
    "        left_weighted_mistakes, left_class = intermediate_node_weighted_mistakes(\n",
    "            left_split[target].as_matrix(), left_data_weights)\n",
    "        right_weighted_mistakes, right_class = intermediate_node_weighted_mistakes(\n",
    "            right_split[target].as_matrix(), right_data_weights)\n",
    "        weighted_error = (left_weighted_mistakes + right_weighted_mistakes) / np.sum(data_weights)\n",
    "        \n",
    "        if weighted_error < best_error:\n",
    "            best_feature = feature\n",
    "            best_error = weighted_error\n",
    "            \n",
    "        return best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, is_leaf=False, prediction=None, left=None, right=None, splitting_feature=None):\n",
    "        self.is_leaf = is_leaf\n",
    "        self.prediction = prediction\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.splitting_feature = splitting_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_leaf(target_values, data_weights):\n",
    "    leaf = Node(is_leaf=True)\n",
    "    weighted_error, best_class = intermediate_node_weighted_mistakes(target_values, data_weights)\n",
    "    \n",
    "    leaf.prediction = best_class\n",
    "    return leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_decision_tree_create(data, features, target, data_weights, current_depth=1, max_depth=10):\n",
    "    remaining_features = features[:]\n",
    "    target_values = data[target]\n",
    "    \n",
    "    if (target_values == 1).all() or (target_values == -1).all():\n",
    "        return create_leaf(target_values, data_weights)\n",
    "    if len(remaining_features) == 0:\n",
    "        return create_leaf(target_values, data_weights)\n",
    "    if current_depth > max_depth:\n",
    "        return create_leaf(target_values, data_weights)\n",
    "    \n",
    "    splitting_feature = best_splitting_feature(data, remaining_features, target, data_weights)\n",
    "    remaining_features.remove(splitting_feature)\n",
    "    \n",
    "    left_split = data[data[splitting_feature] == 0]\n",
    "    right_split = data[data[splitting_feature] == 1]\n",
    "    \n",
    "    left_data_weights = data_weights[np.where(data[splitting_feature] == 0)]\n",
    "    right_data_weights = data_weights[np.where(data[splitting_feature] == 1)]\n",
    "    \n",
    "    if len(left_split) == len(data):\n",
    "        return create_leaf(left_split[target], left_data_weights)\n",
    "    if len(right_split) == len(data):\n",
    "        return create_leaf(right_split[target], right_data_weights)\n",
    "    \n",
    "    left_tree = weighted_decision_tree_create(left_split, remaining_features, target, left_data_weights, \n",
    "                                              current_depth+1, max_depth)\n",
    "    right_tree = weighted_decision_tree_create(right_split, remaining_features, target, right_data_weights,\n",
    "                                              current_depth+1, max_depth)\n",
    "    \n",
    "    return Node(left=left_tree, right=right_tree, splitting_feature=splitting_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_nodes(tree):\n",
    "    if tree.is_leaf:\n",
    "        return 1\n",
    "    return 1 + count_nodes(tree.left) + count_nodes(tree.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify(tree, x, annotate = False):   \n",
    "    # If the node is a leaf node.\n",
    "    if tree.is_leaf:\n",
    "        if annotate: \n",
    "            print(\"At leaf, predicting %s\" % tree.prediction)\n",
    "        return tree.prediction\n",
    "    else:\n",
    "        # Split on feature.\n",
    "        split_feature_value = x[tree.splitting_feature]\n",
    "        if annotate: \n",
    "            print(\"Split on %s = %s\" % (tree.splitting_feature, split_feature_value))\n",
    "        if split_feature_value == 0:\n",
    "            return classify(tree.left, x, annotate)\n",
    "        else:\n",
    "            return classify(tree.right, x, annotate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_classification_error(tree, data, target):\n",
    "    prediction = data.apply(lambda x: classify(tree, x), axis=1)\n",
    "    return np.sum(prediction != data[target]) / float(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_features = train_data.columns.values.tolist()\n",
    "new_features.remove(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example_data_weights = np.zeros(len(train_data))\n",
    "example_data_weights[:10] = 1\n",
    "example_data_weights[-10:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset_20 = weighted_decision_tree_create(train_data, new_features, target, example_data_weights, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5414786159467011"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_error(subset_20, train_data, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
